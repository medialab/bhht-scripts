{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering of Wikipedia Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from unidecode import unidecode\n",
    "from urllib.parse import unquote\n",
    "from fog.clustering import key_collision, sorted_neighborhood\n",
    "from fog.key import fingerprint, omission_key, skeleton_key\n",
    "from fog.phonetics import cologne, rusalka\n",
    "from fog.tokenizers import fingerprint_tokenizer, ngrams\n",
    "from fog.phonetics.utils import squeeze\n",
    "from Levenshtein import distance as levenshtein\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGS = {\n",
    "    'english': 'en',\n",
    "    'french': 'fr',\n",
    "    'spanish': 'es',\n",
    "    'portuguese': 'pt',\n",
    "    'german': 'de',\n",
    "    'italian': 'it',\n",
    "    'swedish': 'sv'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cluster_relevant(cluster, results_index=None):\n",
    "    \"\"\"\n",
    "    Function returning whether a cluster is relevant and the set of found ids.\n",
    "    \n",
    "    A cluster will be deemed relevant if:\n",
    "        1) It contains names from more than one single id.\n",
    "        2) If the range between birth/death does not exceed a given threshold.\n",
    "\n",
    "    \"\"\"\n",
    "    ids = set()\n",
    "    exact_birth_dates = set()\n",
    "    \n",
    "    for person in cluster:\n",
    "        ids.add(person['id'])\n",
    "        \n",
    "        exact_birth_date = person['exact_birth']\n",
    "        \n",
    "        if exact_birth_date is not None:\n",
    "            exact_birth_dates.add(exact_birth_date)\n",
    "\n",
    "    if len(ids) == 1:\n",
    "        return False, ids\n",
    "    \n",
    "    if len(exact_birth_dates) > 1:\n",
    "        return False, ids\n",
    "    \n",
    "    if results_index is not None:\n",
    "        result = results_index.get(tuple(sorted(ids)))\n",
    "\n",
    "        if result is not None:\n",
    "            return False, ids\n",
    "    \n",
    "    return True, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_cluster(cluster):\n",
    "    if len(set(p['birth'] for p in cluster if p['birth'] is not None)) == 1 and \\\n",
    "       len(set(p['death'] for p in cluster if p['death'] is not None)) == 1:\n",
    "        return 'High'\n",
    "    \n",
    "    if any(p for p in cluster if p['exact_birth'] is None):\n",
    "        return 'Low'\n",
    "    \n",
    "    return 'High'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cluster(cluster, ids):\n",
    "    print('Found cluster containing %i ids and %i persons:' % (len(ids), len(cluster)))\n",
    "    \n",
    "    for person in cluster:\n",
    "        print('  %s (%i) (%s - %s) (%s)' % (person['name'], person['id'], person['birth'], person['death'], person['lang']))\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cluster_html(cluster, ids):\n",
    "        \n",
    "    confidence = score_cluster(cluster)\n",
    "    \n",
    "    print('<div>')\n",
    "    print('  <p>')\n",
    "    print('    (%s confidence) Found cluster containing %i ids and %i persons:' % (confidence, len(ids), len(cluster)))\n",
    "    print('  </p>')\n",
    "    \n",
    "    print('  <ul>')\n",
    "    for person in cluster:\n",
    "        link = 'https://%s.wikipedia.org/wiki/%s' % (person['lang'], person['name'])\n",
    "        print('    <li>%s (%i) (%s - %s) (%s) (%s) <u>(<a href=\"%s\" target=\"_blank\">link</a>)</u></li>' % (person['name'], person['id'], person['birth'], person['death'], person['exact_birth'], person['lang'], link))\n",
    "    print('  </ul>')\n",
    "        \n",
    "    print('</div>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e444216ed3e34ad59ec34880ac92ecee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "INPUT = './clustering.csv'\n",
    "BIRTH_DATE_INPUT = './birthdates.csv'\n",
    "OUTPUT = './found.csv'\n",
    "BIRTH_DATE_INDEX = {}\n",
    "PERSONS = []\n",
    "\n",
    "with open(BIRTH_DATE_INPUT, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    \n",
    "    for line in reader:\n",
    "        b = line['birth_date']\n",
    "        \n",
    "        if b.endswith('00-00') or b.endswith('01-01'):\n",
    "            continue\n",
    "        \n",
    "        BIRTH_DATE_INDEX[(line['lang'], line['name'])] = line['birth_date']\n",
    "\n",
    "with open(INPUT, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    \n",
    "    for line in tqdm_notebook(reader):\n",
    "        for lang in LANGS:\n",
    "            name = line['%s_link' % lang]\n",
    "            \n",
    "            if not name:\n",
    "                continue\n",
    "                \n",
    "            person = {\n",
    "                'id': int(line['id']),\n",
    "                'lang': LANGS[lang],\n",
    "                'name': name,\n",
    "                'birth': int(line['birth_min']) if line['birth_min'] else None,\n",
    "                'death': int(line['death_min']) if line['death_min'] else None,\n",
    "                'exact_birth': BIRTH_DATE_INDEX.get((LANGS[lang], name)) or None\n",
    "            }\n",
    "            \n",
    "            PERSONS.append(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_SO_FAR = './clustering_results.csv'\n",
    "RESULTS_INDEX = {}\n",
    "with open(RESULTS_SO_FAR, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    \n",
    "    for line in reader:\n",
    "        ids = tuple(sorted(int(i) for i in line['ids'].split('|')))\n",
    "        \n",
    "        RESULTS_INDEX[ids] = line['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouper(i):\n",
    "    x = PERSONS[i]\n",
    "    \n",
    "    if not x['birth']:\n",
    "        return None\n",
    "    \n",
    "    f = x['name'].lower()\n",
    "    \n",
    "    return (x['birth'], x['death'], f)\n",
    "\n",
    "clusters = key_collision(range(len(PERSONS)), key=grouper)\n",
    "\n",
    "of = open(OUTPUT, 'w')\n",
    "writer = csv.DictWriter(of, fieldnames=['lang', 'name'])\n",
    "writer.writeheader()\n",
    "\n",
    "RELEVANT_CLUSTERS = 0\n",
    "for cluster in clusters:\n",
    "    cluster = [PERSONS[i] for i in cluster]\n",
    "    relevant, ids = is_cluster_relevant(cluster, RESULTS_INDEX)\n",
    "    \n",
    "    if not relevant or score_cluster(cluster) != 'High':\n",
    "        continue\n",
    "        \n",
    "    RELEVANT_CLUSTERS += 1\n",
    "        \n",
    "    print_cluster_html(cluster, ids)\n",
    "    # ids_str = '|'.join(set(str(p['id']) for p in cluster))\n",
    "    # print('high_confidence_cc,%s,oui' % ids_str)\n",
    "    for person in cluster:\n",
    "        writer.writerow({'lang': person['lang'], 'name': person['name']})\n",
    "    \n",
    "print('Found %i relevant clusters' % RELEVANT_CLUSTERS)\n",
    "of.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggressive normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRIP_NONLETTERS_RE = re.compile(r'[^a-z0-9]')\n",
    "\n",
    "def grouper(i):\n",
    "    x = PERSONS[i]\n",
    "    \n",
    "    if not x['birth']:\n",
    "        return None\n",
    "    \n",
    "    f = unquote(x['name'].lower())\n",
    "    \n",
    "    f = re.sub(STRIP_NONLETTERS_RE, '', f)\n",
    "\n",
    "    return (x['birth'], x['death'], f)\n",
    "\n",
    "clusters = key_collision(range(len(PERSONS)), key=grouper)\n",
    "\n",
    "of = open(OUTPUT, 'w')\n",
    "writer = csv.DictWriter(of, fieldnames=['lang', 'name'])\n",
    "writer.writeheader()\n",
    "\n",
    "RELEVANT_CLUSTERS = 0\n",
    "for cluster in clusters:\n",
    "    cluster = [PERSONS[i] for i in cluster]\n",
    "    relevant, ids = is_cluster_relevant(cluster, RESULTS_INDEX)\n",
    "    \n",
    "    if not relevant:\n",
    "        continue\n",
    "        \n",
    "    RELEVANT_CLUSTERS += 1\n",
    "        \n",
    "    print_cluster_html(cluster, ids)\n",
    "\n",
    "    for person in cluster:\n",
    "        writer.writerow({'lang': person['lang'], 'name': person['name']})\n",
    "    \n",
    "print('Found %i relevant clusters' % RELEVANT_CLUSTERS)\n",
    "of.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRIP_NONLETTERS_RE = re.compile(r'[^a-z0-9]')\n",
    "\n",
    "def grouper(i):\n",
    "    x = PERSONS[i]\n",
    "    \n",
    "    if not x['birth']:\n",
    "        return None\n",
    "    \n",
    "    f = unquote(x['name'].lower())\n",
    "    f = unidecode(f)\n",
    "    \n",
    "    f = re.sub(STRIP_NONLETTERS_RE, '', f)\n",
    "\n",
    "    return (x['birth'], x['death'], f)\n",
    "\n",
    "clusters = key_collision(range(len(PERSONS)), key=grouper)\n",
    "\n",
    "of = open(OUTPUT, 'w')\n",
    "writer = csv.DictWriter(of, fieldnames=['lang', 'name'])\n",
    "writer.writeheader()\n",
    "\n",
    "RELEVANT_CLUSTERS = 0\n",
    "for cluster in clusters:\n",
    "    cluster = [PERSONS[i] for i in cluster]\n",
    "    relevant, ids = is_cluster_relevant(cluster, RESULTS_INDEX)\n",
    "    \n",
    "    if not relevant:\n",
    "        continue\n",
    "        \n",
    "    RELEVANT_CLUSTERS += 1\n",
    "        \n",
    "    # print_cluster_html(cluster, ids)\n",
    "    ids_str = '|'.join(set(str(p['id']) for p in cluster))\n",
    "    print('accents,%s,oui' % ids_str)\n",
    "    for person in cluster:\n",
    "        writer.writerow({'lang': person['lang'], 'name': person['name']})\n",
    "    \n",
    "print('Found %i relevant clusters' % RELEVANT_CLUSTERS)\n",
    "of.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fingerprinting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouper(i):\n",
    "    x = PERSONS[i]\n",
    "    \n",
    "    if not x['birth']:\n",
    "        return None\n",
    "    \n",
    "    f = unquote(x['name'])\n",
    "    f = f.replace('_', ' ').replace('-', ' ')\n",
    "    f = fingerprint(f)\n",
    "\n",
    "    return (x['birth'], x['death'], f)\n",
    "\n",
    "clusters = key_collision(range(len(PERSONS)), key=grouper)\n",
    "\n",
    "RELEVANT_CLUSTERS = 0\n",
    "for cluster in clusters:\n",
    "    cluster = [PERSONS[i] for i in cluster]\n",
    "    relevant, ids = is_cluster_relevant(cluster, RESULTS_INDEX)\n",
    "    \n",
    "    if not relevant:\n",
    "        continue\n",
    "        \n",
    "    RELEVANT_CLUSTERS += 1\n",
    "        \n",
    "    print_cluster_html(cluster, ids)\n",
    "    # ids_str = '|'.join(set(str(p['id']) for p in cluster))\n",
    "    # print('accents,%s,oui' % ids_str)\n",
    "    \n",
    "print('Found %i relevant clusters' % RELEVANT_CLUSTERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squeezed fingerprinting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouper(i):\n",
    "    x = PERSONS[i]\n",
    "    \n",
    "    if not x['birth']:\n",
    "        return None\n",
    "    \n",
    "    f = unquote(x['name'])\n",
    "    f = f.replace('_', ' ').replace('-', ' ')\n",
    "    f = squeeze(f)\n",
    "    f = fingerprint(f)\n",
    "\n",
    "    return (x['birth'], x['death'], f)\n",
    "\n",
    "of = open(OUTPUT, 'w')\n",
    "writer = csv.DictWriter(of, fieldnames=['lang', 'name'])\n",
    "writer.writeheader()\n",
    "\n",
    "clusters = key_collision(range(len(PERSONS)), key=grouper)\n",
    "\n",
    "RELEVANT_CLUSTERS = 0\n",
    "for cluster in clusters:\n",
    "    cluster = [PERSONS[i] for i in cluster]\n",
    "    relevant, ids = is_cluster_relevant(cluster, RESULTS_INDEX)\n",
    "    \n",
    "    if not relevant:\n",
    "        continue\n",
    "\n",
    "    RELEVANT_CLUSTERS += 1\n",
    "        \n",
    "    print_cluster_html(cluster, ids)\n",
    "    # ids_str = '|'.join(set(str(p['id']) for p in cluster))\n",
    "    # print('accents,%s,oui' % ids_str)\n",
    "    for person in cluster:\n",
    "        writer.writerow({'lang': person['lang'], 'name': person['name']})\n",
    "    \n",
    "print('Found %i relevant clusters' % RELEVANT_CLUSTERS)\n",
    "of.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trim small tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RE = re.compile('\\d')\n",
    "\n",
    "def grouper(i):\n",
    "    x = PERSONS[i]\n",
    "    \n",
    "    if not x['birth']:\n",
    "        return None\n",
    "    \n",
    "    f = unquote(x['name'])\n",
    "    f = f.replace('_', ' ').replace('-', ' ')\n",
    "    f = squeeze(f)\n",
    "    f = fingerprint_tokenizer(f)\n",
    "    \n",
    "    f = [i for i in f if len(i) > 2]\n",
    "    \n",
    "    if len(f) == 0:\n",
    "        return None\n",
    "    \n",
    "    f = ' '.join(f)\n",
    "    \n",
    "    return (x['birth'], x['death'], f)\n",
    "\n",
    "of = open(OUTPUT, 'w')\n",
    "writer = csv.DictWriter(of, fieldnames=['lang', 'name'])\n",
    "writer.writeheader()\n",
    "\n",
    "clusters = key_collision(range(len(PERSONS)), key=grouper)\n",
    "\n",
    "RELEVANT_CLUSTERS = 0\n",
    "for cluster in clusters:\n",
    "    cluster = [PERSONS[i] for i in cluster]\n",
    "    relevant, ids = is_cluster_relevant(cluster, RESULTS_INDEX)\n",
    "    \n",
    "    if not relevant:\n",
    "        continue\n",
    "\n",
    "    RELEVANT_CLUSTERS += 1\n",
    "        \n",
    "    print_cluster_html(cluster, ids)\n",
    "    # ids_str = '|'.join(set(str(p['id']) for p in cluster))\n",
    "    # print('low_confidence_cc,%s,oui' % ids_str)\n",
    "    for person in cluster:\n",
    "        writer.writerow({'lang': person['lang'], 'name': person['name']})\n",
    "    \n",
    "print('Found %i relevant clusters' % RELEVANT_CLUSTERS)\n",
    "of.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rusalka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RE = re.compile('\\d')\n",
    "\n",
    "def grouper(i):\n",
    "    x = PERSONS[i]\n",
    "    \n",
    "    if not x['birth']:\n",
    "        return None\n",
    "    \n",
    "    f = unquote(x['name'])\n",
    "    f = f.replace('_', ' ').replace('-', ' ')\n",
    "    f = squeeze(f)\n",
    "    f = fingerprint_tokenizer(f)\n",
    "    \n",
    "    f = [i for i in f if not re.match(NUM_RE, i)]\n",
    "    \n",
    "    if len(f) == 0:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        f = ' '.join(rusalka(i) for i in f)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    return (x['birth'], x['death'], f)\n",
    "\n",
    "of = open(OUTPUT, 'w')\n",
    "writer = csv.DictWriter(of, fieldnames=['lang', 'name'])\n",
    "writer.writeheader()\n",
    "\n",
    "clusters = key_collision(range(len(PERSONS)), key=grouper)\n",
    "\n",
    "RELEVANT_CLUSTERS = 0\n",
    "for cluster in clusters:\n",
    "    cluster = [PERSONS[i] for i in cluster]\n",
    "    relevant, ids = is_cluster_relevant(cluster, RESULTS_INDEX)\n",
    "\n",
    "    if not relevant:\n",
    "        continue\n",
    "\n",
    "    RELEVANT_CLUSTERS += 1\n",
    "    \n",
    "    print_cluster_html(cluster, ids)\n",
    "    # ids_str = '|'.join(set(str(p['id']) for p in cluster))\n",
    "    # print('accents,%s,oui' % ids_str)\n",
    "    for person in cluster:\n",
    "        writer.writerow({'lang': person['lang'], 'name': person['name']})\n",
    "\n",
    "print('Found %i relevant clusters' % RELEVANT_CLUSTERS)\n",
    "of.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cologne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RE = re.compile('\\d')\n",
    "\n",
    "def grouper(i):\n",
    "    x = PERSONS[i]\n",
    "    \n",
    "    if not x['birth']:\n",
    "        return None\n",
    "    \n",
    "    f = unquote(x['name'])\n",
    "    f = f.replace('_', ' ').replace('-', ' ')\n",
    "    f = squeeze(f)\n",
    "    f = f.split(' ')\n",
    "    \n",
    "    f = [i for i in f if not re.match(NUM_RE, i)]\n",
    "    \n",
    "    if len(f) == 0:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        f = ' '.join(cologne(i) for i in f)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    return (x['birth'], x['death'], f)\n",
    "\n",
    "of = open(OUTPUT, 'w')\n",
    "writer = csv.DictWriter(of, fieldnames=['lang', 'name'])\n",
    "writer.writeheader()\n",
    "\n",
    "clusters = key_collision(range(len(PERSONS)), key=grouper)\n",
    "\n",
    "RELEVANT_CLUSTERS = 0\n",
    "for cluster in clusters:\n",
    "    cluster = [PERSONS[i] for i in cluster]\n",
    "    relevant, ids = is_cluster_relevant(cluster, RESULTS_INDEX)\n",
    "\n",
    "    if not relevant:\n",
    "        continue\n",
    "        \n",
    "    # if not any(p for p in cluster if p['lang'] == 'de' or p['lang'] == 'sv'):\n",
    "        # continue\n",
    "        \n",
    "    # if any(True for a, b in itertools.combinations([p['name'] for p in cluster], 2) if levenshtein(a, b) > 3):\n",
    "        # continue\n",
    "\n",
    "    RELEVANT_CLUSTERS += 1\n",
    "    \n",
    "    print_cluster_html(cluster, ids)\n",
    "    # ids_str = '|'.join(set(str(p['id']) for p in cluster))\n",
    "    # print('accents,%s,oui' % ids_str)\n",
    "    for person in cluster:\n",
    "        writer.writerow({'lang': person['lang'], 'name': person['name']})\n",
    "\n",
    "print('Found %i relevant clusters' % RELEVANT_CLUSTERS)\n",
    "of.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorted Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "of = open(OUTPUT, 'w')\n",
    "writer = csv.DictWriter(of, fieldnames=['lang', 'name'])\n",
    "writer.writeheader()\n",
    "\n",
    "for p in PERSONS:\n",
    "    p['omission_key'] = omission_key(p['name'])\n",
    "    \n",
    "distance = lambda a, b: levenshtein(PERSONS[a]['name'], PERSONS[b]['name'])\n",
    "\n",
    "def key(i):\n",
    "    p = PERSONS[i]\n",
    "    \n",
    "    return (p['birth'] or 0, p['death'] or 0, p['omission_key'])\n",
    "\n",
    "clusters = list(sorted_neighborhood(range(len(PERSONS)), distance=distance, window=50, radius=1, key=key))\n",
    "\n",
    "RELEVANT_CLUSTERS = 0\n",
    "for cluster in clusters:\n",
    "    cluster = [PERSONS[i] for i in cluster]\n",
    "    \n",
    "    births = set(p['birth'] for p in cluster)\n",
    "    \n",
    "    if len(births) > 1:\n",
    "        continue\n",
    "        \n",
    "    deaths = set(p['death'] for p in cluster if p['death'] is not None)\n",
    "    \n",
    "    if len(deaths) > 1:\n",
    "        continue\n",
    "    \n",
    "    relevant, ids = is_cluster_relevant(cluster, RESULTS_INDEX)\n",
    "\n",
    "    if not relevant:\n",
    "        continue\n",
    "\n",
    "    RELEVANT_CLUSTERS += 1\n",
    "    \n",
    "    print_cluster_html(cluster, ids)\n",
    "    # ids_str = '|'.join(set(str(p['id']) for p in cluster))\n",
    "    # print('accents,%s,oui' % ids_str)\n",
    "    for person in cluster:\n",
    "        writer.writerow({'lang': person['lang'], 'name': person['name']})\n",
    "\n",
    "print('Found %i relevant clusters' % RELEVANT_CLUSTERS)\n",
    "of.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "of = open(OUTPUT, 'w')\n",
    "writer = csv.DictWriter(of, fieldnames=['lang', 'name'])\n",
    "writer.writeheader()\n",
    "\n",
    "for p in PERSONS:\n",
    "    p['skeleton_key'] = skeleton_key(p['name'])\n",
    "    \n",
    "distance = lambda a, b: levenshtein(PERSONS[a]['name'], PERSONS[b]['name'])\n",
    "\n",
    "def key(i):\n",
    "    p = PERSONS[i]\n",
    "    \n",
    "    return (p['birth'] or 0, p['death'] or 0, p['skeleton_key'])\n",
    "\n",
    "clusters = list(sorted_neighborhood(range(len(PERSONS)), distance=distance, window=50, radius=1, key=key))\n",
    "\n",
    "RELEVANT_CLUSTERS = 0\n",
    "for cluster in clusters:\n",
    "    cluster = [PERSONS[i] for i in cluster]\n",
    "    \n",
    "    births = set(p['birth'] for p in cluster)\n",
    "    \n",
    "    if len(births) > 1:\n",
    "        continue\n",
    "        \n",
    "    deaths = set(p['death'] for p in cluster if p['death'] is not None)\n",
    "    \n",
    "    if len(deaths) > 1:\n",
    "        continue\n",
    "    \n",
    "    relevant, ids = is_cluster_relevant(cluster, RESULTS_INDEX)\n",
    "\n",
    "    if not relevant:\n",
    "        continue\n",
    "\n",
    "    RELEVANT_CLUSTERS += 1\n",
    "    \n",
    "    print_cluster_html(cluster, ids)\n",
    "    # ids_str = '|'.join(set(str(p['id']) for p in cluster))\n",
    "    # print('accents,%s,oui' % ids_str)\n",
    "    for person in cluster:\n",
    "        writer.writerow({'lang': person['lang'], 'name': person['name']})\n",
    "\n",
    "print('Found %i relevant clusters' % RELEVANT_CLUSTERS)\n",
    "of.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
